# 分类任务

## 逻辑回归

### 二分类逻辑回归

- 针对分类任务，通常可用概率值估计类别，例如二分类求出一个`0~1`之间的概率，若概率大于某个阈值则取其中一类

  而一般的线性回归会求出超出`0~1`范围的数，这是一种不合理
- 如同之前分析的线性回归问题“数据非线性”的解决方法那样，逻辑回归通过对预测变量作变换来解决分类任务
  
  一元逻辑回归的形式是：

  $$
  p(X)=\frac{e^{\beta_0+\beta_1X}}{1+e^{\beta_0+\beta_1X}}=\frac{1}{1+e^{-\beta_0-\beta_1X}}
  $$

  这在人工智能里称为激活函数`Sigmoid`，其中可将$\beta_0+\beta_1X$替换为多元线性回归的形式来拟合多元分类任务
- 逻辑回归的想法就是将分类任务转换为回归任务
 
  计算估计参数的方法自然是极大似然估计法，处理定性变量和一般线性回归相同，通过设计哑变量来表示

  预测变量和响应变量的相关性通过`Z`统计量及其假设检验计算
- 和线性回归一样，如果预测变量之间高相关，那么容易产生混淆现象

### 多分类逻辑回归

- 和线性回归不同，针对逻辑回归，“多元”一般指多分类，即输出是多个类别
- 使用的激活函数是`Softmax`，`Sigmoid`是`Softmax`的特例：假设输出类别数为`K`，那么第`i`个输出是

  $$
  Softmax(X_i)=\frac{e^{z_i}}{\sum_{k=1}^Ke^{z_k}}
  $$

## 线性判别分析